{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Validate Qualitatively"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5ff1a54c8cd3801"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "from src.config import BASE_LAT_START, BASE_LAT_END, BASE_LON_START, BASE_LON_END\n",
    "from data_transformer import extract_stations_from_nc\n",
    "from data_provider import get_station_indices_map"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b5f5641db4bcbd7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8d483e34f31ab9ba",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "333b3cb6994c5fdc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pred = np.load('predictions/full_pred_plain.npy')\n",
    "# Convert to hecto pascal\n",
    "pred[...,1] = pred[...,1] /100\n",
    "print(pred.shape)\n",
    "\n",
    "ground_truth = xr.load_dataset(\"data_sets/ground_truth.nc\")\n",
    "station_indx_map = get_station_indices_map()\n",
    "gt_stations = extract_stations_from_nc(ground_truth, station_indx_map)  # Is scaled.\n",
    "\n",
    "\n",
    "\n",
    "DATES = pd.date_range('1807-01-01', freq='D', periods=365).values\n",
    "DATES = list(map(lambda d: str(d).split('T')[0], DATES))\n",
    "def date_to_id(date):\n",
    "    return DATES.index(date)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf68fd45f3708515",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f2b1c494315ff8ea",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Average Hottest and Coldest Day according to GT Observations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90a589b034fa522f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(gt_stations)\n",
    "temp_df = temp_df[list(filter(lambda c: \"_ta\" in c,  temp_df.columns))]\n",
    "temp_df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1297ac0af5e71858",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hottest_id = temp_df.mean(axis=1).argmax()\n",
    "coolest_id = temp_df.mean(axis=1).argmin()\n",
    "\n",
    "hottest_date = DATES[hottest_id]\n",
    "coolest_date = DATES[coolest_id]\n",
    "\n",
    "print(f\"Hottest date: {hottest_date} ({hottest_id})\")\n",
    "print(f\"Coolest date: {coolest_date} ({coolest_id})\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6978a5195fc71f3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract anomalies for those two days"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e48acf560e874705"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: based on extract_anomalies(...)\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def extract_ta_cell_anomaly(y_obs, n_doy=365):\n",
    "    \"\"\"\n",
    "    y_obs: one cell over time.\n",
    "    \"\"\"\n",
    "    x_ = np.linspace(0, n_doy - 1, n_doy)  # doy\n",
    "    x1 = np.sin((2 * np.pi * x_) / n_doy)\n",
    "    x2 = np.cos((2 * np.pi * x_) / n_doy)\n",
    "    x3 = np.sin((4 * np.pi * x_) / n_doy)\n",
    "    x4 = np.cos((4 * np.pi * x_) / n_doy)\n",
    "\n",
    "    x = pd.DataFrame(data={'x1': x1, 'x2': x2, 'x3': x3, 'x4': x4})\n",
    "    x_sm = sm.add_constant(x)\n",
    "    model = sm.OLS(y_obs, x_sm).fit()\n",
    "    c0, c1, c2, c3, c4 = model.params\n",
    "    saisonal_component = c0 + c1 * x_sm.x1 + c2 * x_sm.x2 + c3 * x_sm.x3 + c4 * x_sm.x4\n",
    "    desaisonalized = y_obs - saisonal_component\n",
    "    # Insert nans again:\n",
    "   \n",
    "    return desaisonalized.to_numpy()\n",
    "\n",
    "\n",
    "# FOR TEMPERATURE\n",
    "# For each cell, remove seasonality.\n",
    "ta_anomaly = pred[..., 0].copy()\n",
    "for row in range(ta_anomaly.shape[1]):\n",
    "    for column in range(ta_anomaly.shape[2]):\n",
    "        ta_anomaly[:, row, column] = extract_ta_cell_anomaly(ta_anomaly[:, row, column])\n",
    "\n",
    "\n",
    "\n",
    "# FOR PRESSURE\n",
    "# Remove long-term average for each day of the year\n",
    "inference_ymean = np.load(\"../data_sets/ymean_sets/inference_ymean.npy\")\n",
    "# Convert to hecto pascal\n",
    "inference_ymean[...,1] = inference_ymean[...,1] /100\n",
    "slp_anomaly = pred[..., 1] - inference_ymean[..., 1]\n",
    "\n",
    "anomaly = np.concatenate([np.expand_dims(ta_anomaly, axis=-1),\n",
    "                          np.expand_dims(slp_anomaly, axis=-1)], \n",
    "                         axis=-1)\n",
    "print(anomaly.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eabbc81fb8b12f7b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "68f88bc643eb8c0e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Display Climatology and Anomaly Fields"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50c7550a31ee66ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "def display_single_field(pred, anomaly, hot_id, cold_id, hot_date, cold_date, savefig=None):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    \n",
    "    fig.subplots_adjust(right=0.95)\n",
    "    # Pred\n",
    "    ta_hot_pred = pred[hot_id, :, :, 0]\n",
    "    slp_hot_pred = pred[hot_id, :, :, 1]\n",
    "    ta_cold_pred = pred[cold_id, :, :, 0]\n",
    "    slp_cold_pred = pred[cold_id, :, :, 1]\n",
    "    # Anomaly\n",
    "    ta_hot_anomaly = anomaly[hot_id, :, :, 0]\n",
    "    slp_hot_anomaly = anomaly[hot_id, :, :, 1]\n",
    "    ta_cold_anomaly = anomaly[cold_id, :, :, 0]\n",
    "    slp_cold_anomaly = anomaly[cold_id, :, :, 1]\n",
    "    \n",
    "    lon = np.linspace(BASE_LON_START, BASE_LON_END, 64)\n",
    "    lat = np.linspace(BASE_LAT_START, BASE_LAT_END, 32)\n",
    "    \n",
    "    \n",
    "    # === ROW 0 -> Climatology ===\n",
    "    # --- Hot Ta ---\n",
    "    axes[0,0].set_extent((BASE_LON_START, BASE_LON_END, BASE_LAT_START, BASE_LAT_END), crs=ccrs.PlateCarree())\n",
    "    axes[0,0].coastlines(resolution='110m', color='gray')\n",
    "    axes[0,0].set_title(hot_date, fontsize=11)\n",
    "    contourf_1 = axes[0,0].contourf(lon, lat, ta_hot_pred, transform=ccrs.PlateCarree(), levels=100)\n",
    "    #                 tuple (left, bottom, width, height)\n",
    "    sub_ax_1 = fig.add_axes([0.5, 0.53, 0.02, 0.35])\n",
    "    fig.colorbar(contourf_1, cax=sub_ax_1)\n",
    "    # --- Hot SLP ---\n",
    "    # Add slp as contour LINES on top\n",
    "    contourf_1_1 = axes[0,0].contour(lon, lat, slp_hot_pred, transform=ccrs.PlateCarree(), colors='black', levels=7)\n",
    "    axes[0,0].clabel(contourf_1_1, inline=True, fontsize=7)\n",
    "    \n",
    "    # --- Cold Ta ---\n",
    "    axes[0,1].set_extent((BASE_LON_START, BASE_LON_END, BASE_LAT_START, BASE_LAT_END), crs=ccrs.PlateCarree())\n",
    "    axes[0,1].coastlines(resolution='110m', color='gray')\n",
    "    axes[0,1].set_title(cold_date, fontsize=11)\n",
    "    contourf_2 = axes[0,1].contourf(lon, lat, ta_cold_pred, transform=ccrs.PlateCarree(), levels=100)\n",
    "    #                 tuple (left, bottom, width, height)\n",
    "    sub_ax_2 = fig.add_axes([0.95, 0.53, 0.02, 0.35])\n",
    "    fig.colorbar(contourf_2, cax=sub_ax_2)\n",
    "    # --- Cold SLP ---\n",
    "    # Add slp as contour LINES on top\n",
    "    contourf_2_1 = axes[0,1].contour(lon, lat, slp_cold_pred, transform=ccrs.PlateCarree(), colors='black', levels=7)\n",
    "    axes[0,1].clabel(contourf_2_1, inline=True, fontsize=7)\n",
    "    \n",
    "    \n",
    "    # === ROW 1 -> Anomaly ===\n",
    "    # --- Hot Ta ---\n",
    "    axes[1,0].set_extent((BASE_LON_START, BASE_LON_END, BASE_LAT_START, BASE_LAT_END), crs=ccrs.PlateCarree())\n",
    "    axes[1,0].coastlines(resolution='110m', color='gray')\n",
    "    # axes[1,0].set_title(hot_date, fontsize=7)\n",
    "    contourf_3 = axes[1,0].contourf(lon, lat, ta_hot_anomaly, transform=ccrs.PlateCarree(), levels=100)\n",
    "    #                 tuple (left, bottom, width, height)\n",
    "    sub_ax_3 = fig.add_axes([0.5, 0.11, 0.02, 0.35])\n",
    "    fig.colorbar(contourf_3, cax=sub_ax_3)\n",
    "    # --- Hot SLP ---\n",
    "    # Add slp as contour LINES on top\n",
    "    contourf_3_1 = axes[1,0].contour(lon, lat, slp_hot_anomaly, transform=ccrs.PlateCarree(), colors='black', levels=7)\n",
    "    axes[1,0].clabel(contourf_3_1, inline=True, fontsize=7)\n",
    "    \n",
    "    # --- Cold Ta ---\n",
    "    axes[1,1].set_extent((BASE_LON_START, BASE_LON_END, BASE_LAT_START, BASE_LAT_END), crs=ccrs.PlateCarree())\n",
    "    axes[1,1].coastlines(resolution='110m', color='gray')\n",
    "    # axes[1,1].set_title(cold_date, fontsize=7)\n",
    "    contourf_4 = axes[1,1].contourf(lon, lat, ta_cold_anomaly, transform=ccrs.PlateCarree(), levels=100)\n",
    "    #                 tuple (left, bottom, width, height)\n",
    "    sub_ax_4 = fig.add_axes([0.95, 0.11, 0.02, 0.35])\n",
    "    fig.colorbar(contourf_4, cax=sub_ax_4)\n",
    "    # --- Cold SLP ---\n",
    "    # Add slp as contour LINES on top\n",
    "    contourf_4_1 = axes[1,1].contour(lon, lat, slp_cold_anomaly, transform=ccrs.PlateCarree(), colors='black', levels=7)\n",
    "    axes[1,1].clabel(contourf_4_1, inline=True, fontsize=7)\n",
    "    \n",
    "    fig.text(0.11, 0.56, \"Absolute [°C, hPa]\", fontsize=11, rotation=90)\n",
    "    fig.text(0.11, 0.15, \"Anomaly [°C, hPa]\", fontsize=11, rotation=90)\n",
    "\n",
    "    \n",
    "    if savefig:\n",
    "        plt.savefig(\"figures/qualitative_single_fields.png\", \n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0.1,\n",
    "            dpi=300,\n",
    "            )\n",
    "    \n",
    "    \n",
    "display_single_field(pred, anomaly, hottest_id, coolest_id, hottest_date, coolest_date, savefig=True)\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0b9e95165fd8e29",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "63405661f87458a0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c85308dd191778ed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9b90eb8ae4189e9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
